{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Algorithm\n",
    "\n",
    "## Instructions\n",
    "1. From the **Pulse Rate Algorithm** Notebook you can do one of the following:\n",
    "   - Copy over all the **Code** section to the following Code block.\n",
    "   - Download as a Python (`.py`) and copy the code to the following Code block.\n",
    "2. In the bottom right, click the <span style=\"color:blue\">Test Run</span> button. \n",
    "\n",
    "### Didn't Pass\n",
    "If your code didn't pass the test, go back to the previous Concept or to your local setup and continue iterating on your algorithm and try to bring your training error down before testing again.\n",
    "\n",
    "### Pass\n",
    "If your code passes the test, complete the following! You **must** include a screenshot of your code and the Test being **Passed**. Here is what the starter filler code looks like when the test is run and should be similar. A passed test will include in the notebook a green outline plus a box with **Test passed:** and in the Results bar at the bottom the progress bar will be at 100% plus a checkmark with **All cells passed**.\n",
    "![Example](example.png)\n",
    "\n",
    "1. Take a screenshot of your code passing the test, make sure it is in the format `.png`. If not a `.png` image, you will have to edit the Markdown render the image after Step 3. Here is an example of what the `passed.png` would look like \n",
    "2. Upload the screenshot to the same folder or directory as this jupyter notebook.\n",
    "3. Rename the screenshot to `passed.png` and it should show up below.\n",
    "![Passed](passed.png)\n",
    "4. Download this jupyter notebook as a `.pdf` file. \n",
    "5. Continue to Part 2 of the Project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal as sp_signal\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FourierTransform(signal, fs, factor=6):\n",
    "    \"\"\"\n",
    "    Computes the frequencies and the magnitudes of the Fourier Transform\n",
    "    over a signal\n",
    "    \n",
    "    Args:\n",
    "        signal: (np.array) the signal to be transformed\n",
    "        fs: (number) sampling rate\n",
    "    \n",
    "    Returns:\n",
    "        frequencies and magnitudes of the signal\n",
    "    \"\"\"\n",
    "    window_length = factor * len(signal)\n",
    "    \n",
    "    frequencies = np.fft.rfftfreq(window_length, 1 / fs)\n",
    "    fft = np.abs(np.fft.rfft(signal, window_length))\n",
    "    \n",
    "    return frequencies, fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ButterworthFilter(signal, pass_band=(40/60, 240/60), fs=125):\n",
    "    \"\"\"\n",
    "    Butterworth filter algorithm.\n",
    "    \n",
    "    Returns:\n",
    "        Bandpass filtered signal\n",
    "    \"\"\"          \n",
    "    b, a = sp_signal.butter(2, pass_band, btype='bandpass', fs = fs)\n",
    "    return sp_signal.filtfilt(b, a, signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_signal(signal):\n",
    "    signal[signal <= 40/60] = 0\n",
    "    signal[signal >= 240/60] = 0\n",
    "    return signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Featurize(ppg, accx, accy, accz, fs):\n",
    "    \"\"\"\n",
    "    Featurization of the signal\n",
    "    \n",
    "    Args:\n",
    "        ppg: (np.array) photoplethysmography signal\n",
    "        accx: (np.array) x-channel of the accelerometer signal\n",
    "        accy: (np.array) y-channel of the accelerometer signal\n",
    "        accz: (np.array) z-channel of the accelerometer signal\n",
    "        fs: (number) sampling rate of the accelerometer signal\n",
    "    \n",
    "    Returns:\n",
    "        n-tuple of PPG and ACC features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Compute accelerator value with its three channels\n",
    "    acc = np.sqrt(np.sum(np.array([accx, accy, accz]) ** 2, axis=0))\n",
    "    \n",
    "    # Fourier Transform\n",
    "    ppg_freqs, ppg_fft = FourierTransform(ppg, fs)\n",
    "    acc_freqs, acc_fft = FourierTransform(acc, fs)\n",
    "\n",
    "    # Filter ffts\n",
    "    ppg_fft = filter_signal(ppg_fft)\n",
    "    acc_fft = filter_signal(acc_fft)\n",
    "    \n",
    "    # Features\n",
    "    ppg_mean_freq = np.mean(ppg_freqs)\n",
    "    ppg_mean_fft = np.mean(ppg_fft)\n",
    "    ppg_max_freq = ppg_freqs[np.argmax(ppg_fft)]\n",
    "    acc_mean_freq = np.mean(acc_freqs)\n",
    "    acc_mean_fft = np.mean(acc_fft)\n",
    "    acc_max_freq = acc_freqs[np.argmax(acc_fft)]\n",
    "    \n",
    "    return (ppg_mean_freq, \n",
    "            ppg_mean_fft, \n",
    "            ppg_max_freq,\n",
    "            acc_mean_freq,\n",
    "            acc_mean_fft,\n",
    "            acc_max_freq,\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, data_fls, ref_fls, fs=100, window_length=8, window_shift=2):\n",
    "        # Data\n",
    "        self.data_fls = data_fls\n",
    "        self.ref_fls = ref_fls\n",
    "        # Hyperparameters\n",
    "        self.fs = fs\n",
    "        self.window_length = window_length\n",
    "        self.window_shift = window_shift\n",
    "        \n",
    "        if len(self.data_fls) == 0: self.data_fls = ''\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_fls)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Lists to store features, labels and signals\n",
    "        features, labels, signals = [], [], []\n",
    "        \n",
    "        # Extract data\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(self.data_fls[idx])\n",
    "        bpms = sp.io.loadmat(self.ref_fls[idx])['BPM0'][:, 0]\n",
    "\n",
    "        # Process data\n",
    "        total_windows = min(len(ppg), len(bpms))\n",
    "        left_indexes = np.arange(total_windows, dtype=int) * self.fs * self.window_shift\n",
    "        right_indexes = left_indexes + self.fs * self.window_length\n",
    "        \n",
    "        # Iterate over windows\n",
    "        for i, (left, right) in enumerate(zip(left_indexes, right_indexes)):\n",
    "            # Extract portions\n",
    "            ppg_win = ButterworthFilter(ppg[left:right])\n",
    "            accx_win = ButterworthFilter(accx[left:right])\n",
    "            accy_win = ButterworthFilter(accy[left:right])\n",
    "            accz_win = ButterworthFilter(accz[left:right])\n",
    "            # Save features, labels and signals\n",
    "            features.append(Featurize(ppg_win, accx_win, accy_win, accz_win, self.fs))\n",
    "            labels.append(bpms[i])\n",
    "            signals.append([ppg_win, accx_win, accy_win, accz_win])\n",
    "\n",
    "        return features, labels, signals, (ppg, accx, accy, accz)\n",
    "\n",
    "class Estimator():\n",
    "    \"\"\"\n",
    "    Top-level class for the estimator model\n",
    "    \n",
    "    Generates a RandomForestRegressor model and provides functions to interact with it.\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, processor, n_estimators=100, max_depth=10):\n",
    "        # Parameters\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "        # Model\n",
    "        self.model = RandomForestRegressor()\n",
    "        \n",
    "        # Hyperparameters\n",
    "        self.processor = processor\n",
    "    \n",
    "    def train(self):\n",
    "        # Generate features\n",
    "        features, labels, _ = self.generate_features()\n",
    "        # Split dataset\n",
    "        X_train, _, y_train, _ = train_test_split(features, labels, test_size=0.2)\n",
    "\n",
    "        # Train model\n",
    "        self.model.fit(X_train, y_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "            \n",
    "    def generate_features(self):\n",
    "        features, labels, signals = [], [], []\n",
    "\n",
    "        for i in range(len(self.processor)):\n",
    "            _features, _labels, _signals, _ = self.processor[i]\n",
    "            features.extend(_features)\n",
    "            labels.extend(_labels)\n",
    "            signals.extend(_signals)\n",
    "\n",
    "        return np.array(features), np.array(labels), np.array(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "edited": true,
    "gradable": true,
    "grader_id": "nrtnppao4pm",
    "udacity_user_query": ""
   },
   "outputs": [],
   "source": [
    "# replace the code below with your pulse rate algorithm.\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    \"\"\"\n",
    "    Runs the pulse rate algorithm on the given data files, trains a model and evaluates its\n",
    "    performance on the data computing the MAE and the confidence metric.\n",
    "    \"\"\"\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    # Generate classes\n",
    "    processor = DataProcessor(data_fls, ref_fls)\n",
    "    model = Estimator(processor=processor)\n",
    "    # Train model\n",
    "    model.train()\n",
    "\n",
    "    # Predict\n",
    "    errors, confidences = [], []\n",
    "    for i in range(len(processor)):\n",
    "        # Predict\n",
    "        features, labels, signals, _ = processor[i]\n",
    "        predictions = model.predict(features)\n",
    "\n",
    "        _errors, _confidences = [], []\n",
    "        for i in range(predictions.shape[0]):\n",
    "            ppg = ButterworthFilter(signals[i][0])\n",
    "\n",
    "            freqs, fft = FourierTransform(ppg, processor.fs, 2)\n",
    "            fft[fft <= 40/60] = 0\n",
    "            fft[fft >= 240/60] = 0\n",
    "\n",
    "            pred_fs = predictions[i] / 55\n",
    "            pred_fs_win = (freqs >= pred_fs - 0.5) & (freqs <= pred_fs + 0.5)\n",
    "            confs = np.sum(fft[pred_fs_win]) / (np.sum(fft) + 1e-6)\n",
    "            _confidences.append(confs)\n",
    "            _errors.append(np.abs(predictions[i] - labels[i]))\n",
    "        \n",
    "        errors.append(_errors)\n",
    "        confidences.append(_confidences)\n",
    "    \n",
    "    errors = np.hstack(errors)\n",
    "    confidences = np.hstack(confidences)\n",
    "    \n",
    "    return errors, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "grader_mode": "",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "showGradeBtn": true
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
